{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ffc93cb",
   "metadata": {},
   "source": [
    "## test CNN pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8989d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages\n",
    "! pip install requests\n",
    "! pip install json\n",
    "! pip install matplotib.pyplot\n",
    "! pip install time\n",
    "! pip install numpy \n",
    "! pip install yfinance\n",
    "! pip install pandas\n",
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e62985b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import yfinance as yf \n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test CNN takes 256 x 256 image\n",
    "class Torch_CNN(nn.Module):\n",
    "    def __init__(self, embed, num_pred):\n",
    "        super(Torch_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=embed, out_channels=8, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(16 * 64 * 64, num_pred)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = torch.relu(self.conv1(x))  \n",
    "        x = self.pool(x)           \n",
    "        x = torch.relu(self.conv2(x))  \n",
    "        x = self.pool(x)           \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)            \n",
    "        return x\n",
    "\n",
    "\n",
    "## Test FNN takes 4 ts values of shape 4 x 1 and CNN output\n",
    "class Torch_FFN(nn.Module):\n",
    "    def __init__(self, embed, hidden, num_pred):\n",
    "        super(Torch_FFN, self).__init__()  \n",
    "        self.fc1 = nn.Linear(embed, hidden) \n",
    "        self.fc2 = nn.Linear(hidden, num_pred)  \n",
    "    \n",
    "    def forward(self, x):  \n",
    "        x = torch.relu(self.fc1(x))  \n",
    "        x = self.fc2(x)            \n",
    "        return x\n",
    "\n",
    "\n",
    "# test Ens \n",
    "class Torch_Ens(nn.Module):\n",
    "    def __init__(self, embed_img, embed_ts, hidden_dim, num_pred):\n",
    "        super().__init__()\n",
    "        self.cnn = Torch_CNN(embed_img, hidden_dim)  \n",
    "        self.fnn = Torch_FFN(hidden_dim + embed_ts, hidden_dim, num_pred)\n",
    "    \n",
    "    def forward(self, x_img, y_ts):  # CORRECTED: forward (not foward)\n",
    "        x = self.cnn(x_img)\n",
    "        combined = torch.cat([x, y_ts], dim=1)  # On combine \n",
    "        x = self.fnn(combined)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "839130e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([12, 3, 256, 256])\n",
      "Time series shape: torch.Size([12, 4])\n",
      "out shape: torch.Size([12, 1])\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "## El Model\n",
    "model = Torch_Ens(\n",
    "    embed_img=3,     \n",
    "    embed_ts=4,      \n",
    "    hidden_dim=256,  \n",
    "    num_pred=1        \n",
    ")\n",
    "\n",
    "batch_size = 12\n",
    "x_img = torch.randn(batch_size, 3, 256, 256)  \n",
    "x_ts = torch.randn(batch_size, 4)             \n",
    "\n",
    "print(f\"Image shape: {x_img.shape}\")\n",
    "print(f\"Time series shape: {x_ts.shape}\")\n",
    "\n",
    "output = model(x_img, x_ts)\n",
    "print(f\"out shape: {output.shape}\")  # Should be (12, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c90492",
   "metadata": {},
   "outputs": [],
   "source": [
    "## crée un dataset \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "Tickers = [\"ZC=F\", \"ZM=F\", \"GF=F\", \"LE=F\"] #Corn / Soybean / Feeder cattle / live cattle\n",
    "data_price = []\n",
    "for ticker in Tickers:\n",
    "    data = yf.download(ticker,\"2025-02-01\", progress = False, auto_adjust=False, interval=\"1mo\") #1year of data\n",
    "    data_price.append(data['Adj Close'].pct_change().dropna())\n",
    "data_price\n",
    "\n",
    "df = pd.concat(data_price, axis=1)\n",
    "df.columns = [\"Corn\",\"Soy\",\"Cow_food\",\"Cows\"] \n",
    "\n",
    "df.head()\n",
    "\n",
    "def Get_image_data(df):\n",
    "    dates =  df.index.strftime('%Y-%m-%d').tolist() #On change le format\n",
    "\n",
    "    params = {\n",
    "    \"SERVICE\": \"WMS\",\n",
    "    \"REQUEST\": \"GetMap\",\n",
    "    \"VERSION\": \"1.3.0\",\n",
    "    \"LAYERS\":  \"MODIS_Terra_CorrectedReflectance_TrueColor\", #Basic image\n",
    "    \"CRS\": \"EPSG:4326\",\n",
    "    \"BBOX\": \"21,-128,49,-59\",\n",
    "    \"WIDTH\": 256, # On baisse la résolution \n",
    "    \"HEIGHT\": 256,\n",
    "    \"FORMAT\": \"image/png\",\n",
    "    \"TIME\": \"01-01-2020\", \n",
    "    \"TRANSPARENT\": \"FALSE\"\"\"\n",
    "    }\n",
    "\n",
    "    images_dict={}\n",
    "    for i, date in enumerate(dates):\n",
    "        if i > 0:\n",
    "            time.sleep(2)  #On est gentil avec l'API de la Nasa\n",
    "        params['TIME'] = date \n",
    "        print(f\"{params['TIME']}\") \n",
    "        try:\n",
    "            API_endpoint = \"https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi\"\n",
    "            response = requests.get(API_endpoint, params=params, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:  # Success\n",
    "                if response.content.startswith(b'\\x89PNG'):  \n",
    "                    img = mpimg.imread(io.BytesIO(response.content))\n",
    "                    images_dict[date] = img\n",
    "                else:\n",
    "                    print(f\"Response not PNG for {date}\") \n",
    "                    print(response.text[:200]) \n",
    "                    \n",
    "            else:\n",
    "                print(f\"Error {response.status_code} for {date}\")  \n",
    "    \n",
    "        except Exception as e:  \n",
    "            print(f\"Erreur pour {date}: {str(e)}\")  \n",
    "    return images_dict\n",
    "\n",
    "images_dict = Get_image_data(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
